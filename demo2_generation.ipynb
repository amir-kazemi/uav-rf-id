{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c3a888-f096-4db4-b3aa-9b84d9f1455d",
   "metadata": {},
   "source": [
    "# <center> **Generating Synthetic Data** <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf09c689-3202-4d26-9f2a-f1bca1f56b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 17:06:29.324935: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from src import *\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ecd70-6b21-4d95-9083-153a34c573a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ecc711-67c7-4a41-bdfa-7e17f28334d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_percentage = [10, 20, 30, 40, 50]\n",
    "class_size = [4, 10]\n",
    "target_size = 5000\n",
    "\n",
    "# hyperparameters of one-shot generative model\n",
    "patch_dims = [5, 7, 9]\n",
    "min_height = 15\n",
    "\n",
    "# hyperparameters of deep generative models\n",
    "num_epochs = 2000\n",
    "batch_size = 64\n",
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdddbbd-41f4-49b4-9c36-4221d16f5548",
   "metadata": {},
   "source": [
    "## Load subsampled and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e9ea34-da18-4d05-9fa2-7c2d746d8260",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_dict = utils.get_sorted_paths_dict(data_directory  = './data/', substring_to_replace = \"train_subsampled\")\n",
    "paths_dict_test = utils.get_sorted_paths_dict(data_directory  = './data/', substring_to_replace = \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17e9371-0ebf-4464-b1a9-09f245932251",
   "metadata": {},
   "source": [
    "## Generate by one-shot generative model (GPDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76f815-229b-44fb-87b1-c7c4cfb651f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.set_seeds(seed_value=0)\n",
    "\n",
    "for patch_dim in patch_dims:\n",
    "    g = generate.Vicinal(patch_dim = patch_dim, min_height = min_height, algorithm = 'gpdm')\n",
    "    for cs in class_size:\n",
    "        for dp in data_percentage:\n",
    "            for fold in range(5):\n",
    "                print(cs, ' Classes, ', dp, ' Percent, ', 'Fold ', fold)\n",
    "                X_train_subsampled = np.load(paths_dict[(cs, dp)][fold][0])\n",
    "                Y_train_subsampled = np.load(paths_dict[(cs, dp)][fold][1])\n",
    "                X_train_synthetic, Y_train_synthetic = g.generate(X_train_subsampled, Y_train_subsampled, target_size)\n",
    "\n",
    "                # Create the folder if it doesn't exist\n",
    "                folder_path = f'./results/gpdm{patch_dim}/C{cs}P{dp:02d}K{fold + 1}/'\n",
    "                os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "                # Save the synthetic data\n",
    "                np.save(os.path.join(folder_path, 'X_train_synthetic.npy'), X_train_synthetic)\n",
    "                np.save(os.path.join(folder_path, 'Y_train_synthetic.npy'), np.squeeze(Y_train_synthetic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fafbea-9329-43f7-afa4-1debb3666036",
   "metadata": {},
   "source": [
    "## Generate by one-shot generative model (GPNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e943a52b-86c0-4a6d-ac72-8b69bb4f7103",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.set_seeds(seed_value=0)\n",
    "\n",
    "for patch_dim in patch_dims:\n",
    "    g = generate.Vicinal(patch_dim = patch_dim, min_height = min_height, algorithm = 'gpnn')\n",
    "    for cs in class_size:\n",
    "        for dp in data_percentage:\n",
    "            for fold in range(5):\n",
    "                print(cs, ' Classes, ', dp, ' Percent, ', 'Fold ', fold)\n",
    "                X_train_subsampled = np.load(paths_dict[(cs, dp)][fold][0])\n",
    "                Y_train_subsampled = np.load(paths_dict[(cs, dp)][fold][1])\n",
    "                X_train_synthetic, Y_train_synthetic = g.generate(X_train_subsampled, Y_train_subsampled, target_size)\n",
    "\n",
    "                # Create the folder if it doesn't exist\n",
    "                folder_path = f'./results/gpnn{patch_dim}/C{cs}P{dp:02d}K{fold + 1}/'\n",
    "                os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "                # Save the synthetic data\n",
    "                np.save(os.path.join(folder_path, 'X_train_synthetic.npy'), X_train_synthetic)\n",
    "                np.save(os.path.join(folder_path, 'Y_train_synthetic.npy'), np.squeeze(Y_train_synthetic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af675b2-b96f-40ae-9477-0e4561a28822",
   "metadata": {},
   "source": [
    "## Generate by CGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39083e9d-1921-4c3f-8e65-8af3ebe443a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "\n",
    "utils.set_seeds(seed_value=0)\n",
    "\n",
    "folder_path = f'./results/cgan/plots'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "        \n",
    "for cs in class_size:\n",
    "    for idx,dp in enumerate(data_percentage):\n",
    "        for fold in range(5):\n",
    "            \n",
    "            X_test = np.load(paths_dict_test[(cs, dp)][fold][0])\n",
    "            Y_test = np.load(paths_dict_test[(cs, dp)][fold][1])\n",
    "            X_train_subsampled = np.load(paths_dict[(cs, dp)][fold][0])\n",
    "            Y_train_subsampled = np.load(paths_dict[(cs, dp)][fold][1])\n",
    "            \n",
    "            ## Uncomment to clean subsampled data prior to training\n",
    "            #outlier_remover = utils.OutlierRemover(n_mad=3)\n",
    "            #X_train_subsampled, Y_train_subsampled = outlier_remover.remove_outliers(X_train_subsampled,Y_train_subsampled)\n",
    "            \n",
    "            cn = utils.ClasswiseNormalizer(symmetry=True)\n",
    "            X_train_subsampled_normalized =  cn.normalize(X_train_subsampled, Y_train_subsampled)\n",
    "            X_train_subsampled_normalized, Y_train_subsampled_onehot = utils.np2tensor_onehot(\n",
    "                X_train_subsampled_normalized,\n",
    "                Y_train_subsampled,\n",
    "                num_classes=cs)\n",
    "            augmented_X, augmented_Y = utils.generate_mixup_samples(\n",
    "                X_train_subsampled_normalized,\n",
    "                Y_train_subsampled_onehot,\n",
    "                target_size,\n",
    "                alpha=0.2)\n",
    "            dataset = TensorDataset(augmented_X, augmented_Y)\n",
    "            data_loader = DataLoader(dataset, batch_size, shuffle=True, drop_last=False)\n",
    "            \n",
    "            # Initialize CGAN instance\n",
    "            generative_model_instance = generate.Conditional('CGAN', X_train_subsampled.shape[1], cs, latent_dim)\n",
    "            generative_model_instance = generative_model_instance.to(device)\n",
    "            optimizer_G = torch.optim.Adam(generative_model_instance.model.generator.parameters(),lr=lr)\n",
    "            optimizer_D = torch.optim.Adam(generative_model_instance.model.discriminator.parameters(),lr=lr)\n",
    "            \n",
    "            # Train CGAN\n",
    "            generative_model_instance.model.train_model(data_loader, optimizer_G, optimizer_D, num_epochs)\n",
    "            \n",
    "            # Generate synthetic data using CGAN\n",
    "            X_train_synthetic_normalized, Y_train_synthetic = generative_model_instance.generate(num_samples=target_size)\n",
    "            X_train_synthetic = cn.denormalize(X_train_synthetic_normalized, Y_train_synthetic)\n",
    "\n",
    "            # Create the folder if it doesn't exist\n",
    "            folder_path = f'./results/cgan/C{cs}P{dp:02d}K{fold + 1}/'\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "            \n",
    "            loss_plot = plt.gcf()\n",
    "            loss_plot.savefig(f'./results/cgan/plots/loss_C{cs}P{dp:02d}K{fold + 1}.pdf')\n",
    "            \n",
    "            # Extracting dimensions from the data\n",
    "            m, f = X_train_subsampled.shape\n",
    "            n, _ = X_train_synthetic.shape\n",
    "            c = cs # Total number of unique classes\n",
    "            \n",
    "            print(cs, ' Classes, ', dp, ' Percent, ', 'Fold ', fold)\n",
    "            # Create a subplot of shape c*2\n",
    "            fig, axes = plt.subplots(c, 3, figsize=(10, 4*c))\n",
    "\n",
    "            # Iterate over each class and plot data\n",
    "            for cls in range(c):\n",
    "                # Subsampled data\n",
    "                mask_subsampled = Y_train_subsampled == cls\n",
    "                axes[cls][0].plot(range(f), X_train_subsampled[mask_subsampled].T, alpha=0.25)\n",
    "                axes[cls][0].set_title(f\"Class {cls} Subsampled\")\n",
    "                \n",
    "                # Synthetic data\n",
    "                mask_synthetic = Y_train_synthetic == cls\n",
    "                axes[cls][1].plot(range(f), X_train_synthetic[mask_synthetic].T, alpha=0.25)\n",
    "                axes[cls][1].set_title(f\"Class {cls} Synthetic\")\n",
    "\n",
    "                # test data\n",
    "                mask_test = Y_test == cls\n",
    "                axes[cls][2].plot(range(f), X_test[mask_test].T, alpha=0.25)\n",
    "                axes[cls][2].set_title(f\"Class {cls} Test\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            fig.savefig(f'./results/cgan/plots/sample_C{cs}P{dp:02d}K{fold + 1}.pdf')\n",
    "            \n",
    "\n",
    "            # Save the synthetic data\n",
    "            np.save(os.path.join(folder_path, 'X_train_synthetic.npy'), X_train_synthetic)\n",
    "            np.save(os.path.join(folder_path, 'Y_train_synthetic.npy'), np.squeeze(Y_train_synthetic))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4931878e-beb2-43af-8fa0-4f8903dcc0d3",
   "metadata": {},
   "source": [
    "## Generate by CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a892b2c-b47b-4e4c-8c23-2c6366283fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "utils.set_seeds(seed_value=0)\n",
    "\n",
    "folder_path = f'./results/cvae/plots'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "for cs in class_size:\n",
    "    for idx, dp in enumerate(data_percentage):\n",
    "        for fold in range(5):\n",
    "            \n",
    "            # Load and preprocess data as before\n",
    "            X_test = np.load(paths_dict_test[(cs, dp)][fold][0])\n",
    "            Y_test = np.load(paths_dict_test[(cs, dp)][fold][1])\n",
    "            X_train_subsampled = np.load(paths_dict[(cs, dp)][fold][0])\n",
    "            Y_train_subsampled = np.load(paths_dict[(cs, dp)][fold][1])\n",
    "            \n",
    "            ## Uncomment to clean subsampled data prior to training\n",
    "            #outlier_remover = utils.OutlierRemover(n_mad=3)\n",
    "            #X_train_subsampled, Y_train_subsampled = outlier_remover.remove_outliers(X_train_subsampled,Y_train_subsampled)\n",
    "            \n",
    "            cn = utils.ClasswiseNormalizer(symmetry=True)\n",
    "            X_train_subsampled_normalized =  cn.normalize(X_train_subsampled, Y_train_subsampled)\n",
    "            X_train_subsampled_normalized, Y_train_subsampled_onehot = utils.np2tensor_onehot(\n",
    "                X_train_subsampled_normalized,\n",
    "                Y_train_subsampled,\n",
    "                num_classes=cs)\n",
    "            augmented_X, augmented_Y = utils.generate_mixup_samples(\n",
    "                X_train_subsampled_normalized,\n",
    "                Y_train_subsampled_onehot,\n",
    "                target_size,\n",
    "                alpha=0.2)\n",
    "            dataset = TensorDataset(augmented_X, augmented_Y)\n",
    "            data_loader = DataLoader(dataset, batch_size, shuffle=True, drop_last=False)\n",
    "            \n",
    "            # Initialize CVAE instance\n",
    "            generative_model_instance = generate.Conditional('CVAE', X_train_subsampled.shape[1], cs, latent_dim)\n",
    "            generative_model_instance = generative_model_instance.to(device)\n",
    "            optimizer = torch.optim.Adam(generative_model_instance.model.parameters(), lr)\n",
    "            \n",
    "            # Train CVAE\n",
    "            generative_model_instance.model.train_model(data_loader, optimizer, num_epochs)\n",
    "\n",
    "            # Generate synthetic data using CVAE\n",
    "            X_train_synthetic_normalized, Y_train_synthetic = generative_model_instance.generate(target_size)\n",
    "            X_train_synthetic = cn.denormalize(X_train_synthetic_normalized, Y_train_synthetic)\n",
    "            \n",
    "            # Create the folder if it doesn't exist\n",
    "            folder_path = f'./results/cvae/C{cs}P{dp:02d}K{fold + 1}/'\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "            \n",
    "            loss_plot = plt.gcf()\n",
    "            loss_plot.savefig(f'./results/cvae/plots/loss_C{cs}P{dp:02d}K{fold + 1}.pdf')\n",
    "            \n",
    "            # Extracting dimensions from the data\n",
    "            m, f = X_train_subsampled.shape\n",
    "            n, _ = X_train_synthetic.shape\n",
    "            c = cs # Total number of unique classes\n",
    "            \n",
    "            print(cs, ' Classes, ', dp, ' Percent, ', 'Fold ', fold)\n",
    "            # Create a subplot of shape c*2\n",
    "            fig, axes = plt.subplots(c, 3, figsize=(10, 4*c))\n",
    "\n",
    "            # Iterate over each class and plot data\n",
    "            for cls in range(c):\n",
    "                # Subsampled data\n",
    "                mask_subsampled = Y_train_subsampled == cls\n",
    "                axes[cls][0].plot(range(f), X_train_subsampled[mask_subsampled].T, alpha=0.25)\n",
    "                axes[cls][0].set_title(f\"Class {cls} Subsampled\")\n",
    "                \n",
    "                # Synthetic data\n",
    "                mask_synthetic = Y_train_synthetic == cls\n",
    "                axes[cls][1].plot(range(f), X_train_synthetic[mask_synthetic].T, alpha=0.25)\n",
    "                axes[cls][1].set_title(f\"Class {cls} Synthetic\")\n",
    "\n",
    "                # test data\n",
    "                mask_test = Y_test == cls\n",
    "                axes[cls][2].plot(range(f), X_test[mask_test].T, alpha=0.25)\n",
    "                axes[cls][2].set_title(f\"Class {cls} Test\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            fig.savefig(f'./results/cvae/plots/sample_C{cs}P{dp:02d}K{fold + 1}.pdf')\n",
    "            \n",
    "\n",
    "            # Save the synthetic data\n",
    "            np.save(os.path.join(folder_path, 'X_train_synthetic.npy'), X_train_synthetic)\n",
    "            np.save(os.path.join(folder_path, 'Y_train_synthetic.npy'), np.squeeze(Y_train_synthetic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uav-rf-id)",
   "language": "python",
   "name": "uav-rf-id"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
